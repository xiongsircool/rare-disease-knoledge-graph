#!/usr/bin/env python3
"""
ç½•è§ç–¾ç—…æ–‡çŒ®ç®¡ç†å™¨
æ•´åˆPubMedæ‘˜è¦å’ŒPMCå…¨æ–‡ä¸‹è½½åŠŸèƒ½
æä¾›ç»Ÿä¸€çš„æ–‡çŒ®è·å–å’Œç®¡ç†æ¥å£
"""

import os
import time
import json
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass

from .pubmed_downloader import PubMedDownloader, PubMedConfig
from .optimized_pmc_downloader import OptimizedPMCDownloader, OptimizedPMCConfig


@dataclass
class LiteratureConfig:
    """æ–‡çŒ®ä¸‹è½½ç»Ÿä¸€é…ç½®"""
    email: str
    api_key: Optional[str] = None
    base_output_dir: str = "literature_data"

    # PubMedé…ç½®
    pubmed_batch_size: int = 1000
    pubmed_disease_batch_size: int = 50
    pubmed_sleep_time: float = 0.34
    pubmed_max_workers: int = 3

    # PMCé…ç½®
    pmc_batch_size: int = 500
    pmc_disease_batch_size: int = 20
    pmc_sleep_time: float = 0.34
    pmc_max_records_per_search: int = 10000

    # é€šç”¨é…ç½®
    max_retry: int = 3
    request_timeout: int = 30


class LiteratureManager:
    """ç½•è§ç–¾ç—…æ–‡çŒ®ç®¡ç†å™¨"""

    def __init__(self, config: LiteratureConfig):
        self.config = config
        self.setup_directories()
        self.init_downloaders()

    def setup_directories(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        self.base_dir = Path(self.config.base_output_dir)
        self.pubmed_dir = self.base_dir / "pubmed"
        self.pmc_dir = self.base_dir / "pmc"
        self.integrated_dir = self.base_dir / "integrated"
        self.metadata_dir = self.base_dir / "metadata"

        for dir_path in [self.base_dir, self.pubmed_dir, self.pmc_dir,
                        self.integrated_dir, self.metadata_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

    def init_downloaders(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        # PubMedä¸‹è½½å™¨é…ç½®
        pubmed_config = PubMedConfig(
            email=self.config.email,
            api_key=self.config.api_key,
            output_dir=str(self.pubmed_dir),
            batch_size=self.config.pubmed_batch_size,
            disease_batch_size=self.config.pubmed_disease_batch_size,
            sleep_time=self.config.pubmed_sleep_time,
            max_workers=self.config.pubmed_max_workers,
            max_retry=self.config.max_retry,
            request_timeout=self.config.request_timeout
        )

        # PMCä¸‹è½½å™¨é…ç½®
        pmc_config = OptimizedPMCConfig(
            email=self.config.email,
            api_key=self.config.api_key,
            output_dir=str(self.pmc_dir),
            batch_size=self.config.pmc_batch_size,
            disease_batch_size=self.config.pmc_disease_batch_size,
            sleep_time=self.config.pmc_sleep_time,
            max_records_per_search=self.config.pmc_max_records_per_search,
            max_retry=self.config.max_retry
        )

        self.pubmed_downloader = PubMedDownloader(pubmed_config)
        self.pmc_downloader = OptimizedPMCDownloader(pmc_config)

    def load_disease_list(self, disease_file: str) -> List[str]:
        """åŠ è½½ç½•è§ç–¾ç—…åˆ—è¡¨"""
        with open(disease_file, 'r', encoding='utf-8') as f:
            diseases = [line.strip() for line in f if line.strip()]
        print(f"[INFO] åŠ è½½äº† {len(diseases)} ä¸ªç½•è§ç–¾ç—…")
        return diseases

    def download_pubmed_abstracts(self, diseases: List[str]) -> List[Dict]:
        """ä¸‹è½½PubMedæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“„ å¼€å§‹ä¸‹è½½PubMedæ‘˜è¦")
        print("="*60)

        return self.pubmed_downloader.process_diseases_batch(diseases)

    def download_pmc_fulltext(self, diseases: List[str]) -> List[Dict]:
        """ä¸‹è½½PMCå…¨æ–‡"""
        print("\n" + "="*60)
        print("ğŸ“š å¼€å§‹ä¸‹è½½PMCå…¨æ–‡")
        print("="*60)

        return self.pmc_downloader.process_diseases_batch(diseases)

    def download_both_sources(self, diseases: List[str]) -> Dict:
        """åŒæ—¶ä¸‹è½½PubMedæ‘˜è¦å’ŒPMCå…¨æ–‡"""
        print("\n" + "="*80)
        print("ğŸ”¬ ç½•è§ç–¾ç—…æ–‡çŒ®æ‰¹é‡ä¸‹è½½ - åŒæ•°æ®æº")
        print("="*80)

        results = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'diseases_processed': diseases,
            'total_diseases': len(diseases),
            'start_time': time.time(),
            'pubmed_results': None,
            'pmc_results': None,
            'integrated_summary': None
        }

        # ä¸‹è½½PubMedæ‘˜è¦
        try:
            results['pubmed_results'] = self.download_pubmed_abstracts(diseases)
        except Exception as e:
            print(f"[ERROR] PubMedä¸‹è½½å¤±è´¥: {e}")
            results['pubmed_results'] = []

        # ä¸‹è½½PMCå…¨æ–‡
        try:
            results['pmc_results'] = self.download_pmc_fulltext(diseases)
        except Exception as e:
            print(f"[ERROR] PMCä¸‹è½½å¤±è´¥: {e}")
            results['pmc_results'] = []

        # ç”Ÿæˆæ•´åˆæ€»ç»“
        results['end_time'] = time.time()
        results['total_time'] = results['end_time'] - results['start_time']
        results['integrated_summary'] = self.generate_integrated_summary(results)

        # ä¿å­˜å®Œæ•´ç»“æœ
        self.save_integrated_results(results)

        return results

    def generate_integrated_summary(self, results: Dict) -> Dict:
        """ç”Ÿæˆæ•´åˆæ€»ç»“"""
        pubmed_results = results.get('pubmed_results', [])
        pmc_results = results.get('pmc_results', [])

        # ç»Ÿè®¡PubMedç»“æœ
        pubmed_successful = [r for r in pubmed_results if r.get('success', False)]
        pubmed_failed = [r for r in pubmed_results if not r.get('success', False)]
        total_pmids = sum(r.get('pmids_found', 0) for r in pubmed_successful)
        total_abstracts = sum(r.get('articles_downloaded', 0) for r in pubmed_successful)

        # ç»Ÿè®¡PMCç»“æœ
        pmc_successful = [r for r in pmc_results if r.get('success', False)]
        pmc_failed = [r for r in pmc_results if not r.get('success', False)]
        total_pmc_ids = sum(r.get('pmc_ids_found', 0) for r in pmc_successful)
        total_fulltext = sum(r.get('articles_downloaded', 0) for r in pmc_successful)

        # æ‰¾å‡ºå…±åŒæˆåŠŸçš„ç–¾ç—…
        pubmed_diseases = {r['disease'] for r in pubmed_successful}
        pmc_diseases = {r['disease'] for r in pmc_successful}
        common_diseases = pubmed_diseases.intersection(pmc_diseases)

        return {
            'processing_summary': {
                'total_diseases': len(results['diseases_processed']),
                'total_time_minutes': results['total_time'] / 60,
                'average_time_per_disease': results['total_time'] / len(results['diseases_processed'])
            },
            'pubmed_summary': {
                'successful_diseases': len(pubmed_successful),
                'failed_diseases': len(pubmed_failed),
                'total_pmids_found': total_pmids,
                'total_abstracts_downloaded': total_abstracts,
                'success_rate': len(pubmed_successful) / len(pubmed_results) if pubmed_results else 0
            },
            'pmc_summary': {
                'successful_diseases': len(pmc_successful),
                'failed_diseases': len(pmc_failed),
                'total_pmc_ids_found': total_pmc_ids,
                'total_fulltext_downloaded': total_fulltext,
                'success_rate': len(pmc_successful) / len(pmc_results) if pmc_results else 0
            },
            'coverage_analysis': {
                'diseases_with_pubmed_only': len(pubmed_diseases - pmc_diseases),
                'diseases_with_pmc_only': len(pmc_diseases - pubmed_diseases),
                'diseases_with_both_sources': len(common_diseases),
                'diseases_with_no_data': len(results['diseases_processed']) - len(pubmed_diseases.union(pmc_diseases))
            },
            'data_quality': {
                'avg_abstracts_per_disease': total_abstracts / len(pubmed_successful) if pubmed_successful else 0,
                'avg_fulltext_per_disease': total_fulltext / len(pmc_successful) if pmc_successful else 0,
                'total_literature_items': total_abstracts + total_fulltext
            }
        }

    def save_integrated_results(self, results: Dict):
        """ä¿å­˜æ•´åˆç»“æœ"""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        results_file = self.metadata_dir / f"integrated_results_{timestamp}.json"

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"\n[INFO] æ•´åˆç»“æœå·²ä¿å­˜: {results_file}")

        # ç”Ÿæˆç®€è¦æŠ¥å‘Š
        report_file = self.metadata_dir / f"summary_report_{timestamp}.txt"
        self.generate_text_report(results, report_file)

    def generate_text_report(self, results: Dict, report_file: Path):
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        summary = results['integrated_summary']

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("ç½•è§ç–¾ç—…æ–‡çŒ®ä¸‹è½½æŠ¥å‘Š\n")
            f.write("="*50 + "\n\n")
            f.write(f"ä¸‹è½½æ—¶é—´: {results['timestamp']}\n")
            f.write(f"å¤„ç†ç–¾ç—…æ•°: {results['total_diseases']}\n")
            f.write(f"æ€»ç”¨æ—¶: {results['total_time']:.1f} ç§’ ({results['total_time']/60:.1f} åˆ†é’Ÿ)\n\n")

            # PubMedæ‘˜è¦ç»Ÿè®¡
            pubmed_summary = summary['pubmed_summary']
            f.write("ğŸ“„ PubMedæ‘˜è¦ä¸‹è½½ç»Ÿè®¡:\n")
            f.write(f"  æˆåŠŸç–¾ç—…: {pubmed_summary['successful_diseases']}\n")
            f.write(f"  å¤±è´¥ç–¾ç—…: {pubmed_summary['failed_diseases']}\n")
            f.write(f"  æ‰¾åˆ°PMID: {pubmed_summary['total_pmids_found']}\n")
            f.write(f"  ä¸‹è½½æ‘˜è¦: {pubmed_summary['total_abstracts_downloaded']}\n")
            f.write(f"  æˆåŠŸç‡: {pubmed_summary['success_rate']:.1%}\n\n")

            # PMCå…¨æ–‡ç»Ÿè®¡
            pmc_summary = summary['pmc_summary']
            f.write("ğŸ“š PMCå…¨æ–‡ä¸‹è½½ç»Ÿè®¡:\n")
            f.write(f"  æˆåŠŸç–¾ç—…: {pmc_summary['successful_diseases']}\n")
            f.write(f"  å¤±è´¥ç–¾ç—…: {pmc_summary['failed_diseases']}\n")
            f.write(f"  æ‰¾åˆ°PMC ID: {pmc_summary['total_pmc_ids_found']}\n")
            f.write(f"  ä¸‹è½½å…¨æ–‡: {pmc_summary['total_fulltext_downloaded']}\n")
            f.write(f"  æˆåŠŸç‡: {pmc_summary['success_rate']:.1%}\n\n")

            # æ•°æ®è¦†ç›–åˆ†æ
            coverage = summary['coverage_analysis']
            f.write("ğŸ“Š æ•°æ®è¦†ç›–åˆ†æ:\n")
            f.write(f"  ä»…æœ‰æ‘˜è¦çš„ç–¾ç—…: {coverage['diseases_with_pubmed_only']}\n")
            f.write(f"  ä»…æœ‰å…¨æ–‡çš„ç–¾ç—…: {coverage['diseases_with_pmc_only']}\n")
            f.write(f"  åŒæ•°æ®æºç–¾ç—…: {coverage['diseases_with_both_sources']}\n")
            f.write(f"  æ— æ•°æ®ç–¾ç—…: {coverage['diseases_with_no_data']}\n\n")

            # æ•°æ®è´¨é‡è¯„ä¼°
            quality = summary['data_quality']
            f.write("ğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°:\n")
            f.write(f"  å¹³å‡æ‘˜è¦æ•°/ç–¾ç—…: {quality['avg_abstracts_per_disease']:.1f}\n")
            f.write(f"  å¹³å‡å…¨æ–‡æ•°/ç–¾ç—…: {quality['avg_fulltext_per_disease']:.1f}\n")
            f.write(f"  æ€»æ–‡çŒ®æ¡ç›®: {quality['total_literature_items']}\n\n")

            f.write(f"ğŸ“ æ•°æ®ä¿å­˜ä½ç½®:\n")
            f.write(f"  PubMedæ‘˜è¦: {self.pubmed_dir}\n")
            f.write(f"  PMCå…¨æ–‡: {self.pmc_dir}\n")
            f.write(f"  å…ƒæ•°æ®: {self.metadata_dir}\n")

        print(f"[INFO] æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    def print_final_summary(self, results: Dict):
        """æ‰“å°æœ€ç»ˆæ€»ç»“"""
        summary = results['integrated_summary']
        proc_summary = summary['processing_summary']

        print("\n" + "="*80)
        print("ğŸ‰ ç½•è§ç–¾ç—…æ–‡çŒ®ä¸‹è½½å®Œæˆï¼")
        print("="*80)

        print(f"ğŸ“… å¤„ç†æ—¶é—´: {results['timestamp']}")
        print(f"ğŸ”¬ å¤„ç†ç–¾ç—…: {proc_summary['total_diseases']} ä¸ª")
        print(f"â±ï¸  æ€»ç”¨æ—¶: {proc_summary['total_time_minutes']:.1f} åˆ†é’Ÿ")
        print(f"âš¡ å¹³å‡é€Ÿåº¦: {proc_summary['average_time_per_disease']:.1f} ç§’/ç–¾ç—…")

        print(f"\nğŸ“„ PubMedæ‘˜è¦:")
        pubmed = summary['pubmed_summary']
        print(f"   âœ… æˆåŠŸ: {pubmed['successful_diseases']} ç–¾ç—…")
        print(f"   ğŸ“Š æ‘˜è¦: {pubmed['total_abstracts_downloaded']} ç¯‡")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {pubmed['success_rate']:.1%}")

        print(f"\nğŸ“š PMCå…¨æ–‡:")
        pmc = summary['pmc_summary']
        print(f"   âœ… æˆåŠŸ: {pmc['successful_diseases']} ç–¾ç—…")
        print(f"   ğŸ“Š å…¨æ–‡: {pmc['total_fulltext_downloaded']} ç¯‡")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {pmc['success_rate']:.1%}")

        coverage = summary['coverage_analysis']
        print(f"\nğŸ“Š æ•°æ®è¦†ç›–:")
        print(f"   ğŸ”„ åŒæ•°æ®æº: {coverage['diseases_with_both_sources']} ç–¾ç—…")
        print(f"   ğŸ“„ ä»…æ‘˜è¦: {coverage['diseases_with_pubmed_only']} ç–¾ç—…")
        print(f"   ğŸ“š ä»…å…¨æ–‡: {coverage['diseases_with_pmc_only']} ç–¾ç—…")
        print(f"   âŒ æ— æ•°æ®: {coverage['diseases_with_no_data']} ç–¾ç—…")

        print(f"\nğŸ“ æ–‡ä»¶ä½ç½®:")
        print(f"   ğŸ“‚ æ•°æ®ç›®å½•: {self.base_dir}")
        print(f"   ğŸ“‹ æŠ¥å‘Šæ–‡ä»¶: {self.metadata_dir}")

        print("="*80)


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    print("ğŸ§¬ ç½•è§ç–¾ç—…æ–‡çŒ®ç®¡ç†å™¨ç¤ºä¾‹")
    print("="*50)

    # é…ç½®
    config = LiteratureConfig(
        email="1666526339@qq.com",  # è¯·æ›¿æ¢ä¸ºä½ çš„é‚®ç®±
        api_key=None,  # å¯é€‰ï¼šNCBI API key
        base_output_dir="rare_disease_literature",

        # å°è§„æ¨¡æµ‹è¯•é…ç½®
        pubmed_disease_batch_size=5,  # æ¯æ‰¹å¤„ç†5ä¸ªç–¾ç—…
        pmc_disease_batch_size=5,
        pubmed_max_workers=2,         # é™ä½å¹¶å‘æ•°
    )

    print(f"ğŸ“§ é‚®ç®±: {config.email}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.base_output_dir}")

    # æ£€æŸ¥é‚®ç®±é…ç½®
    if config.email == "your_email@example.com":
        print("\nâŒ è¯·å…ˆé…ç½®ä½ çš„é‚®ç®±åœ°å€ï¼")
        return

    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = LiteratureManager(config)

    # åŠ è½½ç–¾ç—…åˆ—è¡¨
    disease_file = "/Users/xiong/Documents/github/rare-disease-knowledge-graph/all_rare_disease_names.txt"
    all_diseases = manager.load_disease_list(disease_file)

    # é€‰æ‹©æµ‹è¯•ç–¾ç—…
    test_diseases = all_diseases[:3]  # åªå¤„ç†å‰3ä¸ªç–¾ç—…ä½œä¸ºæµ‹è¯•

    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šå¤„ç†å‰ {len(test_diseases)} ä¸ªç–¾ç—…")
    print("ğŸ“‹ ç–¾ç—…åˆ—è¡¨:")
    for i, disease in enumerate(test_diseases, 1):
        print(f"   {i}. {disease}")

    # ç¡®è®¤ç»§ç»­
    response = input(f"\nâ“ ç¡®å®šè¦å¼€å§‹ä¸‹è½½å—ï¼Ÿ(y/N): ").strip().lower()
    if response not in ['y', 'yes']:
        print("âŒ ç”¨æˆ·å–æ¶ˆä¸‹è½½")
        return

    try:
        # æ‰§è¡Œä¸‹è½½
        results = manager.download_both_sources(test_diseases)

        # æ‰“å°æœ€ç»ˆæ€»ç»“
        manager.print_final_summary(results)

    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    print(f"\nğŸ‰ ç¤ºä¾‹å®Œæˆï¼")


if __name__ == "__main__":
    main()