# 罕见疾病文献下载脚本使用指南

本目录包含两个主要的文献下载脚本，采用不同的策略来提高下载效率。

## 📁 脚本概览

### 1. `optimized_download_literature.py` - 优化版脚本
- **策略**: 两阶段去重策略（顺序收集 + 批量下载）
- **适用场景**: 稳定的网络环境，注重数据完整性
- **特点**: 逐个处理疾病，支持断点续传，生成CSV文件

### 2. `concurrent_download_literature.py` - 并发版脚本
- **策略**: 三阶段策略（并发收集 + 批量下载）
- **适用场景**: 高性能环境，注重处理速度
- **特点**: 多线程并发处理，大幅提升检索速度

## 🚀 使用方法

### 运行优化版脚本
```bash
cd /data/xxy/xxy/github/rare-disease-knowledge-graph/knowledge_graph/tasks
python optimized_download_literature.py
```

### 运行并发版脚本
```bash
cd /data/xxy/xxy/github/rare-disease-knowledge-graph/knowledge_graph/tasks
python concurrent_download_literature.py
```

## ⚙️ 脚本配置选项

### 下载模式选择
两个脚本都支持三种下载模式：
1. **📄 仅下载PubMed摘要** - 获取文献摘要信息
2. **📚 仅下载PMC全文** - 获取开放获取的全文
3. **🔄 同时下载** - 同时获取摘要和全文

### 并发版脚本特有配置
并发版脚本提供额外的并发配置选项：
1. **🐌 低并发 (2-3 线程)** - 适用于不稳定网络
2. **🚶 中等并发 (5-8 线程)** - 适用于一般使用
3. **🏃 高并发 (10-15 线程)** - 适用于稳定高速网络
4. **🚀 自定义** - 用户自定义并发数 (1-20)

## 📊 性能对比

| 特性 | 优化版脚本 | 并发版脚本 |
|------|------------|------------|
| 处理方式 | 顺序处理 | 并发处理 |
| 处理速度 | 中等 | 快 |
| 资源占用 | 低 | 中等 |
| 网络压力 | 小 | 大 |
| 适用场景 | 通用 | 高性能环境 |
| API限制友好 | ✅ | ⚠️ 需要配置 |

## 📁 输出文件结构

```
knowledge_graph/data/literature/
├── PMC_full_text/                           # PMC全文数据
│   ├── batch_downloads/                     # 批次下载文件
│   ├── parsed_json/                         # 解析后的JSON文件
│   ├── csv_by_disease/                      # 按疾病分拆的CSV文件
│   └── optimized_pmc_unified_*.csv          # PMC统一CSV文件
├── PubMed_abstracts/                        # PubMed摘要数据
│   ├── batch_downloads/                     # 批次下载文件
│   ├── abstracts/                           # 按疾病分拆的摘要文件
│   ├── csv_by_disease/                      # 按疾病分拆的CSV文件
│   └── optimized_pubmed_unified_*.csv       # PubMed统一CSV文件
├── progress_state.pkl                       # 断点续传文件（优化版）
├── concurrent_progress_state.pkl            # 断点续传文件（并发版）
├── disease_pmc_mapping.json                 # 疾病-PMC映射关系
├── optimization_report_*.json               # 优化报告（优化版）
└── concurrent_report_*.json                 # 并发报告（并发版）
```

## 🔧 关键功能

### 断点续传
- 两个脚本都支持断点续传功能
- 自动保存处理进度，中断后可继续
- 避免重复处理已完成的疾病

### 去重优化
- 自动去除重复的文献ID
- 建立疾病-文献映射关系
- 大幅减少实际下载量

### CSV导出
- 生成易于查看的CSV文件
- 支持按疾病分拆和统一文件两种格式
- 包含完整的文献元数据

## 📈 使用建议

### 初次使用建议
1. **小规模测试**: 先用 50-100 个疾病测试
2. **观察日志**: 关注处理速度和错误率
3. **检查结果**: 验证生成的文件是否正确

### 大规模使用建议
1. **网络环境**: 确保网络稳定，特别是使用并发版时
2. **存储空间**: 预留足够的磁盘空间
3. **处理时间**: 大规模下载可能需要数小时

### 并发版使用注意事项
1. **API限制**: 注意PubMed/PMC的API请求频率限制
2. **网络稳定性**: 并发请求对网络要求较高
3. **系统资源**: 监控CPU和内存使用情况

## 🛠️ 故障排除

### 常见问题

**Q: 脚本运行很慢怎么办？**
A: 可以尝试增加并发数（并发版），或检查网络连接质量。

**Q: 出现API限制错误怎么办？**
A: 减少并发数，增加请求间隔时间，或切换到优化版脚本。

**Q: 如何恢复中断的下载？**
A: 重新运行脚本，会自动检测并从中断处继续。

**Q: 生成的文件太大怎么办？**
A: 按疾病分拆的CSV文件可以帮助管理大文件，也可以分批处理疾病。

## 📞 技术支持

如遇到问题，请检查：
1. 网络连接是否正常
2. API密钥是否有效
3. 磁盘空间是否充足
4. Python环境是否正确配置

## 🔄 版本历史

- **v1.0**: 基础下载功能
- **v2.0**: 优化版脚本，支持两阶段去重
- **v3.0**: 并发版脚本，支持多线程处理
- **v3.1**: 增强CSV导出和断点续传功能