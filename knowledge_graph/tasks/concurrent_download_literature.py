#!/usr/bin/env python3
"""
å¹¶å‘ç‰ˆç½•è§ç–¾ç—…æ–‡çŒ®ä¸‹è½½è„šæœ¬
é‡‡ç”¨ä¸‰é˜¶æ®µç­–ç•¥ï¼š
1. é˜¶æ®µä¸€ï¼šå¹¶å‘æ”¶é›†æ‰€æœ‰ç–¾ç—…çš„æ–‡çŒ®IDï¼Œå»é‡
2. é˜¶æ®µäºŒï¼šæ‰¹é‡ä¸‹è½½å»é‡åçš„PMCå…¨æ–‡
3. é˜¶æ®µä¸‰ï¼šæ‰¹é‡ä¸‹è½½å»é‡åçš„PubMedæ‘˜è¦
"""

import os
import sys
import time
import json
import pickle
import threading
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Set, Tuple
from collections import defaultdict
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import signal

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
src_dir = project_root / "src"
sys.path.insert(0, str(src_dir))

from literature_downloader import OptimizedPMCDownloader, OptimizedPMCConfig, PubMedDownloader, PubMedConfig


@dataclass
class DiseaseLiteratureInfo:
    """ç–¾ç—…æ–‡çŒ®ä¿¡æ¯"""
    disease: str
    search_terms: List[str]
    pmc_ids: List[str]
    pmids: List[str]
    pmc_count: int
    pmid_count: int
    processing_time: float
    success: bool
    error: Optional[str] = None


@dataclass
class LiteratureMetadata:
    """æ–‡çŒ®å…ƒæ•°æ®"""
    pmc_id: str = ""
    pmid: str = ""
    title: str = ""
    authors: List[str] = None
    journal: str = ""
    publication_date: str = ""
    abstract: str = ""
    doi: str = ""
    related_diseases: List[str] = None

    def __post_init__(self):
        if self.authors is None:
            self.authors = []
        if self.related_diseases is None:
            self.related_diseases = []


class ConcurrentLiteratureDownloader:
    """å¹¶å‘ç‰ˆæ–‡çŒ®ä¸‹è½½å™¨"""

    def __init__(self, download_mode: str = "pmc_only", max_workers: int = 5):
        """
        åˆå§‹åŒ–é…ç½®

        Args:
            download_mode: ä¸‹è½½æ¨¡å¼
                - "pmc_only": ä»…ä¸‹è½½PMCå…¨æ–‡
                - "pubmed_only": ä»…ä¸‹è½½PubMedæ‘˜è¦
                - "both": åŒæ—¶ä¸‹è½½PubMedæ‘˜è¦å’ŒPMCå…¨æ–‡
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
        """
        self.email = "1666526339@qq.com"
        self.api_key = "f7f3e5ffa36e0446a4a3c6540d8fa7e72808"
        self.download_mode = download_mode
        self.max_workers = max_workers

        # è¾“å‡ºç›®å½•
        self.base_output_dir = project_root / "knowledge_graph" / "data" / "literature"
        self.base_output_dir.mkdir(parents=True, exist_ok=True)

        # çº¿ç¨‹é”
        self.data_lock = threading.Lock()
        self.progress_lock = threading.Lock()

        # åˆå§‹åŒ–ä¸‹è½½å™¨
        self.init_downloaders()

        # æ•°æ®å­˜å‚¨
        self.disease_literature_mapping: Dict[str, DiseaseLiteratureInfo] = {}
        self.unique_pmc_ids: Set[str] = set()
        self.unique_pmids: Set[str] = set()
        self.literature_disease_mapping: Dict[str, List[str]] = defaultdict(list)
        self.literature_metadata: Dict[str, LiteratureMetadata] = {}

        # è¿›åº¦è·Ÿè¸ª
        self.processed_count = 0
        self.successful_count = 0
        self.failed_count = 0

        # æ–­ç‚¹ç»­ä¼ æ–‡ä»¶è·¯å¾„
        self.progress_file = self.base_output_dir / "concurrent_progress_state.pkl"
        self.disease_pmc_mapping_file = self.base_output_dir / "disease_pmc_mapping.json"

        # æ§åˆ¶æ ‡å¿—
        self.should_stop = False

        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        print(f"\nâš ï¸  æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        self.should_stop = True

    def init_downloaders(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        # PMCä¸‹è½½å™¨é…ç½®
        if self.download_mode in ["pmc_only", "both"]:
            self.pmc_config = OptimizedPMCConfig(
                email=self.email,
                api_key=self.api_key,
                output_dir=str(self.base_output_dir / "PMC_full_text"),
                batch_size=500,
                disease_batch_size=50,
                max_records_per_search=100000,
                sleep_time=0.34,
                sleep_time_with_key=0.12,
                max_retry=3,
                save_parsed_json=True,
                save_raw_xml=True,
                parse_detailed_content=True
            )
            self.pmc_downloader = OptimizedPMCDownloader(self.pmc_config)

        # PubMedä¸‹è½½å™¨é…ç½®
        if self.download_mode in ["pubmed_only", "both"]:
            self.pubmed_config = PubMedConfig(
                email=self.email,
                api_key=self.api_key,
                output_dir=str(self.base_output_dir / "PubMed_abstracts"),
                max_records_per_search=100000,
                batch_size=1000,
                disease_batch_size=50,
                sleep_time=0.34,
                sleep_time_with_key=0.12,
                max_retry=3,
                request_timeout=30,
                max_workers=3
            )
            self.pubmed_downloader = PubMedDownloader(self.pubmed_config)

    def load_progress_state(self) -> Dict:
        """åŠ è½½è¿›åº¦çŠ¶æ€"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'rb') as f:
                    state = pickle.load(f)
                print(f"ğŸ“‚ å‘ç°æœ‰æ–­ç‚¹æ–‡ä»¶ï¼Œå·²å¤„ç† {len(state.get('processed_diseases', []))} ä¸ªç–¾ç—…")
                return state
            except Exception as e:
                print(f"âš ï¸  æ–­ç‚¹æ–‡ä»¶æŸåï¼Œé‡æ–°å¼€å§‹: {e}")
        return {}

    def save_progress_state(self, processed_diseases: List[str]):
        """ä¿å­˜è¿›åº¦çŠ¶æ€"""
        try:
            with self.progress_lock:
                state = {
                    'processed_diseases': processed_diseases,
                    'disease_literature_mapping': self.disease_literature_mapping,
                    'unique_pmc_ids': list(self.unique_pmc_ids),
                    'unique_pmids': list(self.unique_pmids),
                    'literature_disease_mapping': dict(self.literature_disease_mapping),
                    'processed_count': self.processed_count,
                    'successful_count': self.successful_count,
                    'failed_count': self.failed_count,
                    'timestamp': datetime.now().isoformat()
                }

                with open(self.progress_file, 'wb') as f:
                    pickle.dump(state, f)

        except Exception as e:
            print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    def save_disease_pmc_mapping(self):
        """ä¿å­˜ç–¾ç—…-PMC IDæ˜ å°„å…³ç³»"""
        mapping_data = {}
        with self.data_lock:
            for disease, info in self.disease_literature_mapping.items():
                if info.success and info.pmc_ids:
                    mapping_data[disease] = {
                        'pmc_ids': info.pmc_ids,
                        'pmc_count': len(info.pmc_ids),
                        'pmids': info.pmids,
                        'pmid_count': len(info.pmids),
                        'processing_time': info.processing_time,
                        'last_updated': datetime.now().isoformat()
                    }

        try:
            with open(self.disease_pmc_mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ ç–¾ç—…-PMCæ˜ å°„å…³ç³»å·²ä¿å­˜: {self.disease_pmc_mapping_file}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç–¾ç—…-PMCæ˜ å°„å¤±è´¥: {e}")

    def load_disease_list(self) -> List[str]:
        """åŠ è½½ç½•è§ç–¾ç—…åˆ—è¡¨"""
        disease_file = project_root / "all_rare_disease_names.txt"
        print(f"ğŸ“‹ åŠ è½½ç–¾ç—…åˆ—è¡¨: {disease_file}")

        with open(disease_file, 'r', encoding='utf-8') as f:
            diseases = [line.strip() for line in f if line.strip()]

        print(f"âœ… åŠ è½½äº† {len(diseases)} ä¸ªç½•è§ç–¾ç—…")
        return diseases

    def collect_single_disease_literature(self, disease: str) -> DiseaseLiteratureInfo:
        """æ”¶é›†å•ä¸ªç–¾ç—…çš„æ–‡çŒ®IDï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if self.should_stop:
            # è¿”å›ä¸€ä¸ªå¤±è´¥çš„ç»“æœ
            return DiseaseLiteratureInfo(
                disease=disease,
                search_terms=[disease],
                pmc_ids=[],
                pmids=[],
                pmc_count=0,
                pmid_count=0,
                processing_time=0,
                success=False,
                error="Process stopped"
            )

        disease_info = DiseaseLiteratureInfo(
            disease=disease,
            search_terms=[disease],
            pmc_ids=[],
            pmids=[],
            pmc_count=0,
            pmid_count=0,
            processing_time=0,
            success=False
        )

        start_time = time.time()

        try:
            # PMCæ£€ç´¢
            if self.download_mode in ["pmc_only", "both"]:
                # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„ä¸‹è½½å™¨å®ä¾‹
                pmc_downloader = OptimizedPMCDownloader(self.pmc_config)
                pmc_ids = pmc_downloader.collect_pmc_ids_only(disease)
                disease_info.pmc_ids = pmc_ids
                disease_info.pmc_count = len(pmc_ids)

            # PubMedæ£€ç´¢
            if self.download_mode in ["pubmed_only", "both"]:
                # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„ä¸‹è½½å™¨å®ä¾‹
                pubmed_downloader = PubMedDownloader(self.pubmed_config)
                try:
                    pmids = pubmed_downloader.search_pubmed(disease)
                    disease_info.pmids = pmids
                    disease_info.pmid_count = len(pmids)
                except Exception as e:
                    print(f"   âŒ PubMedæ£€ç´¢å¤±è´¥ {disease}: {e}")

            disease_info.success = True

        except Exception as e:
            disease_info.error = str(e)

        disease_info.processing_time = time.time() - start_time
        return disease_info

    def process_disease_result(self, disease_info: DiseaseLiteratureInfo):
        """å¤„ç†å•ä¸ªç–¾ç—…çš„æ£€ç´¢ç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.data_lock:
            # ä¿å­˜ç»“æœ
            self.disease_literature_mapping[disease_info.disease] = disease_info

            if disease_info.success:
                self.successful_count += 1

                # æ·»åŠ åˆ°å»é‡é›†åˆ
                self.unique_pmc_ids.update(disease_info.pmc_ids)
                self.unique_pmids.update(disease_info.pmids)

                # å»ºç«‹æ–‡çŒ®-ç–¾ç—…æ˜ å°„
                for pmc_id in disease_info.pmc_ids:
                    self.literature_disease_mapping[pmc_id].append(disease_info.disease)
                for pmid in disease_info.pmids:
                    self.literature_disease_mapping[pmid].append(disease_info.disease)
            else:
                self.failed_count += 1

            self.processed_count += 1

    def stage_one_concurrent_collect(self, diseases: List[str], max_diseases: Optional[int] = None):
        """é˜¶æ®µä¸€ï¼šå¹¶å‘æ”¶é›†æ‰€æœ‰ç–¾ç—…çš„æ–‡çŒ®ID"""
        if max_diseases:
            diseases = diseases[:max_diseases]

        # åŠ è½½è¿›åº¦çŠ¶æ€
        progress_state = self.load_progress_state()
        processed_diseases = set(progress_state.get('processed_diseases', []))

        # æ¢å¤ä¹‹å‰çš„çŠ¶æ€
        if progress_state:
            with self.data_lock:
                self.disease_literature_mapping = progress_state.get('disease_literature_mapping', {})
                self.unique_pmc_ids = set(progress_state.get('unique_pmc_ids', []))
                self.unique_pmids = set(progress_state.get('unique_pmids', []))
                self.literature_disease_mapping = defaultdict(list, progress_state.get('literature_disease_mapping', {}))
                self.processed_count = progress_state.get('processed_count', 0)
                self.successful_count = progress_state.get('successful_count', 0)
                self.failed_count = progress_state.get('failed_count', 0)

        # è¿‡æ»¤æœªå¤„ç†çš„ç–¾ç—…
        remaining_diseases = [d for d in diseases if d not in processed_diseases]

        if not remaining_diseases:
            print("âœ… æ‰€æœ‰ç–¾ç—…å·²å¤„ç†å®Œæ¯•ï¼")
            return

        print(f"\nğŸš€ é˜¶æ®µä¸€ï¼šå¹¶å‘æ”¶é›†æ–‡çŒ®ID")
        print(f"ğŸ“Š æ€»ç–¾ç—…æ•°: {len(diseases)}, å·²å¤„ç†: {len(processed_diseases)}, å‰©ä½™: {len(remaining_diseases)}")
        print(f"ğŸ”§ å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)

        start_time = time.time()

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_disease = {
                executor.submit(self.collect_single_disease_literature, disease): disease
                for disease in remaining_diseases
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_disease):
                if self.should_stop:
                    break

                disease = future_to_disease[future]
                try:
                    disease_info = future.result()
                    self.process_disease_result(disease_info)

                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (self.processed_count / len(diseases)) * 100
                    print(f"ğŸ“Š è¿›åº¦: {self.processed_count}/{len(diseases)} ({progress:.1f}%) - "
                          f"âœ…{self.successful_count} âŒ{self.failed_count} - {disease[:50]}...")

                    # æ¯10ä¸ªç–¾ç—…ä¿å­˜ä¸€æ¬¡è¿›åº¦
                    if self.processed_count % 10 == 0:
                        processed_diseases.add(disease)
                        self.save_progress_state(list(processed_diseases))
                        self.save_disease_pmc_mapping()

                except Exception as e:
                    print(f"âŒ å¤„ç†ç–¾ç—… {disease} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    with self.data_lock:
                        self.failed_count += 1
                        self.processed_count += 1

                # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.1)

        # æœ€ç»ˆä¿å­˜è¿›åº¦
        final_processed = processed_diseases.union(set(remaining_diseases[:self.processed_count - len(processed_diseases)]))
        self.save_progress_state(list(final_processed))
        self.save_disease_pmc_mapping()

        collection_time = time.time() - start_time

        print(f"\nâœ… é˜¶æ®µä¸€å®Œæˆï¼")
        print(f"â° ç”¨æ—¶: {collection_time:.1f} ç§’")
        print(f"ğŸ“Š æˆåŠŸæ”¶é›†: {self.successful_count} ä¸ªç–¾ç—…")
        print(f"âŒ æ”¶é›†å¤±è´¥: {self.failed_count} ä¸ªç–¾ç—…")
        print(f"ğŸ” å»é‡å‰ PMC IDs: {sum(len(info.pmc_ids) for info in self.disease_literature_mapping.values())}")
        print(f"ğŸ” å»é‡å‰ PubMed IDs: {sum(len(info.pmids) for info in self.disease_literature_mapping.values())}")
        print(f"âœ¨ å»é‡å PMC IDs: {len(self.unique_pmc_ids)}")
        print(f"âœ¨ å»é‡å PubMed IDs: {len(self.unique_pmids)}")

        # è®¡ç®—å»é‡æ•ˆæœ
        original_pmc = sum(len(info.pmc_ids) for info in self.disease_literature_mapping.values())
        original_pmid = sum(len(info.pmids) for info in self.disease_literature_mapping.values())

        if original_pmc > 0:
            pmc_reduction = (original_pmc - len(self.unique_pmc_ids)) / original_pmc * 100
            print(f"ğŸ“ˆ PMC IDå»é‡ç‡: {pmc_reduction:.1f}%")

        if original_pmid > 0:
            pmid_reduction = (original_pmid - len(self.unique_pmids)) / original_pmid * 100
            print(f"ğŸ“ˆ PubMed IDå»é‡ç‡: {pmid_reduction:.1f}%")

    def stage_two_batch_download(self):
        """é˜¶æ®µäºŒï¼šæ‰¹é‡ä¸‹è½½å»é‡åçš„æ–‡çŒ®"""
        if self.should_stop:
            print("âš ï¸  æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œè·³è¿‡ä¸‹è½½é˜¶æ®µ")
            return

        print(f"\nğŸš€ é˜¶æ®µäºŒï¼šæ‰¹é‡ä¸‹è½½å»é‡åçš„æ–‡çŒ®")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)

        start_time = time.time()

        # PMCæ‰¹é‡ä¸‹è½½
        if self.download_mode in ["pmc_only", "both"] and self.unique_pmc_ids:
            print(f"\nğŸ“š å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(self.unique_pmc_ids)} ä¸ªPMCå…¨æ–‡...")
            self.batch_download_pmc_articles()

        # PubMedæ‰¹é‡ä¸‹è½½
        if self.download_mode in ["pubmed_only", "both"] and self.unique_pmids:
            print(f"\nğŸ“„ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(self.unique_pmids)} ä¸ªPubMedæ‘˜è¦...")
            self.batch_download_pubmed_abstracts()

        download_time = time.time() - start_time

        print(f"\nâœ… é˜¶æ®µäºŒå®Œæˆï¼")
        print(f"â° ç”¨æ—¶: {download_time:.1f} ç§’")

    def batch_download_pmc_articles(self):
        """æ‰¹é‡ä¸‹è½½PMCæ–‡ç« ï¼ˆç®€åŒ–ç‰ˆï¼Œå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        if not self.unique_pmc_ids or self.should_stop:
            print("   â„¹ï¸  æ²¡æœ‰PMCæ–‡ç« éœ€è¦ä¸‹è½½æˆ–å·²åœæ­¢")
            return

        # è¿™é‡Œå¯ä»¥å¤ç”¨åŸæœ‰çš„PMCæ‰¹é‡ä¸‹è½½é€»è¾‘
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶åªæ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"   ğŸ“š éœ€è¦ä¸‹è½½ {len(self.unique_pmc_ids)} ä¸ªPMCå…¨æ–‡")
        print(f"   ğŸ’¡ å»ºè®®è¿è¡ŒåŸæœ‰çš„æ‰¹é‡ä¸‹è½½è„šæœ¬å®Œæˆä¸‹è½½")

    def batch_download_pubmed_abstracts(self):
        """æ‰¹é‡ä¸‹è½½PubMedæ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼Œå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        if not self.unique_pmids or self.should_stop:
            print("   â„¹ï¸  æ²¡æœ‰PubMedæ‘˜è¦éœ€è¦ä¸‹è½½æˆ–å·²åœæ­¢")
            return

        # è¿™é‡Œå¯ä»¥å¤ç”¨åŸæœ‰çš„PubMedæ‰¹é‡ä¸‹è½½é€»è¾‘
        print(f"   ğŸ“„ éœ€è¦ä¸‹è½½ {len(self.unique_pmids)} ä¸ªPubMedæ‘˜è¦")
        print(f"   ğŸ’¡ å»ºè®®è¿è¡ŒåŸæœ‰çš„æ‰¹é‡ä¸‹è½½è„šæœ¬å®Œæˆä¸‹è½½")

    def save_final_report(self):
        """ä¿å­˜æœ€ç»ˆæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = self.base_output_dir / f"concurrent_report_{timestamp}.json"

        # ç»Ÿè®¡ä¿¡æ¯
        total_diseases = len(self.disease_literature_mapping)
        successful_diseases = sum(1 for info in self.disease_literature_mapping.values() if info.success)

        # è®¡ç®—é‡å¤æƒ…å†µ
        total_original_pmc = sum(len(info.pmc_ids) for info in self.disease_literature_mapping.values())
        total_original_pmid = sum(len(info.pmids) for info in self.disease_literature_mapping.values())

        report = {
            'concurrent_summary': {
                'strategy': 'concurrent_collection_batch_download',
                'timestamp': timestamp,
                'max_workers': self.max_workers,
                'total_diseases_processed': total_diseases,
                'successful_diseases': successful_diseases,
                'success_rate': (successful_diseases / total_diseases * 100) if total_diseases > 0 else 0,
                'processing_time': self.processed_count
            },
            'deduplication_stats': {
                'pmc_original_count': total_original_pmc,
                'pmc_deduplicated_count': len(self.unique_pmc_ids),
                'pmc_reduction_percentage': ((total_original_pmc - len(self.unique_pmc_ids)) / total_original_pmc * 100) if total_original_pmc > 0 else 0,
                'pubmed_original_count': total_original_pmid,
                'pubmed_deduplicated_count': len(self.unique_pmids),
                'pubmed_reduction_percentage': ((total_original_pmid - len(self.unique_pmids)) / total_original_pmid * 100) if total_original_pmid > 0 else 0
            },
            'performance_stats': {
                'processed_count': self.processed_count,
                'successful_count': self.successful_count,
                'failed_count': self.failed_count,
                'concurrent_efficiency': f"{self.successful_count}/{self.processed_count}"
            }
        }

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“Š å¹¶å‘ä¸‹è½½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        self.display_concurrent_summary(report)

    def display_concurrent_summary(self, report: Dict):
        """æ˜¾ç¤ºå¹¶å‘ä¸‹è½½æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“Š å¹¶å‘æ–‡çŒ®ä¸‹è½½ä¼˜åŒ–æŠ¥å‘Š")
        print("="*80)

        summary = report['concurrent_summary']
        dedup = report['deduplication_stats']
        perf = report['performance_stats']

        print(f"ğŸ“… å¤„ç†æ—¶é—´: {summary['timestamp']}")
        print(f"ğŸ”§ å¹¶å‘çº¿ç¨‹æ•°: {summary['max_workers']}")
        print(f"ğŸ”¬ å¤„ç†ç–¾ç—…: {summary['total_diseases_processed']}")
        print(f"âœ… æˆåŠŸæ”¶é›†: {summary['successful_diseases']} ({summary['success_rate']:.1f}%)")
        print()

        print("ğŸ¯ å»é‡æ•ˆæœ:")
        print(f"   ğŸ“š PMC: {dedup['pmc_original_count']} â†’ {dedup['pmc_deduplicated_count']} (å‡å°‘ {dedup['pmc_reduction_percentage']:.1f}%)")
        print(f"   ğŸ“„ PubMed: {dedup['pubmed_original_count']} â†’ {dedup['pubmed_deduplicated_count']} (å‡å°‘ {dedup['pubmed_reduction_percentage']:.1f}%)")
        print()

        print("âš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   ğŸ“Š å¤„ç†ç»Ÿè®¡: {perf['processed_count']} æ€»è®¡")
        print(f"   âœ… æˆåŠŸ/å¤±è´¥: {perf['successful_count']}/{perf['failed_count']}")
        print(f"   ğŸ¯ æˆåŠŸç‡: {perf['concurrent_efficiency']}")
        print()

        print("ğŸ’¡ å¹¶å‘ä¼˜åŠ¿:")
        print("   âœ… å¹¶å‘æ”¶é›†ï¼Œå¤§å¹…æå‡æ£€ç´¢é€Ÿåº¦")
        print("   âœ… çº¿ç¨‹å®‰å…¨ï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§")
        print("   âœ… æ–­ç‚¹ç»­ä¼ ï¼Œæ”¯æŒä¸­æ–­æ¢å¤")
        print("   âœ… å»é‡ä¼˜åŒ–ï¼Œé¿å…é‡å¤ä¸‹è½½")
        print("="*80)

    def run_concurrent_download(self, diseases: List[str], max_diseases: Optional[int] = None):
        """è¿è¡Œå¹¶å‘ä¸‹è½½æµç¨‹"""
        print("ğŸ§¬ å¹¶å‘ç‰ˆç½•è§ç–¾ç—…æ–‡çŒ®ä¸‹è½½å·¥å…·")
        print("âš¡ é‡‡ç”¨å¹¶å‘æ”¶é›† + æ‰¹é‡ä¸‹è½½ç­–ç•¥")
        print("="*50)

        try:
            # é˜¶æ®µä¸€ï¼šå¹¶å‘æ”¶é›†æ–‡çŒ®ID
            self.stage_one_concurrent_collect(diseases, max_diseases)

            if self.should_stop:
                print("âš ï¸  ç”¨æˆ·ä¸­æ–­äº†æ”¶é›†è¿‡ç¨‹")
                return

            # é˜¶æ®µäºŒï¼šæ‰¹é‡ä¸‹è½½
            self.stage_two_batch_download()

            # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
            self.save_final_report()

            print(f"\nğŸ‰ å¹¶å‘ä¸‹è½½å®Œæˆï¼")
            print(f"ğŸ’¡ å¯æŸ¥çœ‹ä¸‹è½½çš„æ–‡çŒ®æ•°æ®å’Œå¹¶å‘æŠ¥å‘Š")

        except KeyboardInterrupt:
            print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ä¸‹è½½è¿‡ç¨‹")
            # å³ä½¿ä¸­æ–­ä¹Ÿè¦ä¿å­˜å·²æ”¶é›†çš„æ•°æ®
            if self.disease_literature_mapping:
                self.save_progress_state([])
                self.save_final_report()
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¬ å¹¶å‘ç‰ˆç½•è§ç–¾ç—…æ–‡çŒ®ä¸‹è½½å·¥å…·")
    print("="*50)

    # é€‰æ‹©ä¸‹è½½æ¨¡å¼
    print("è¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:")
    print("1. ğŸ“„ ä»…ä¸‹è½½PubMedæ‘˜è¦")
    print("2. ğŸ“š ä»…ä¸‹è½½PMCå…¨æ–‡")
    print("3. ğŸ”„ åŒæ—¶ä¸‹è½½PubMedæ‘˜è¦å’ŒPMCå…¨æ–‡")

    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-3): ").strip()
            if choice == '1':
                download_mode = "pubmed_only"
                break
            elif choice == '2':
                download_mode = "pmc_only"
                break
            elif choice == '3':
                download_mode = "both"
                break
            else:
                print("âŒ è¯·è¾“å…¥ 1-3 ä¹‹é—´çš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆï¼Œé€€å‡ºç¨‹åº")
            return

    # é€‰æ‹©å¹¶å‘æ•°é‡
    print(f"\nè¯·é€‰æ‹©å¹¶å‘çº¿ç¨‹æ•°:")
    print("1. ğŸŒ ä½å¹¶å‘ (2-3 çº¿ç¨‹ï¼Œæ¨èç”¨äºä¸ç¨³å®šç½‘ç»œ)")
    print("2. ğŸš¶ ä¸­ç­‰å¹¶å‘ (5-8 çº¿ç¨‹ï¼Œæ¨èç”¨äºä¸€èˆ¬ä½¿ç”¨)")
    print("3. ğŸƒ é«˜å¹¶å‘ (10-15 çº¿ç¨‹ï¼Œæ¨èç”¨äºç¨³å®šç½‘ç»œ)")
    print("4. ğŸš€ è‡ªå®šä¹‰å¹¶å‘æ•°")

    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-4): ").strip()
            if choice == '1':
                max_workers = 3
                break
            elif choice == '2':
                max_workers = 6
                break
            elif choice == '3':
                max_workers = 12
                break
            elif choice == '4':
                max_workers = int(input("è¯·è¾“å…¥è‡ªå®šä¹‰å¹¶å‘æ•° (1-20): ").strip())
                if 1 <= max_workers <= 20:
                    break
                else:
                    print("âŒ å¹¶å‘æ•°åº”åœ¨ 1-20 ä¹‹é—´")
            else:
                print("âŒ è¯·è¾“å…¥ 1-4 ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆï¼Œé€€å‡ºç¨‹åº")
            return

    print(f"\nğŸš€ é€‰æ‹©äº†å¹¶å‘ä¸‹è½½æ¨¡å¼: {download_mode}, çº¿ç¨‹æ•°: {max_workers}")
    downloader = ConcurrentLiteratureDownloader(download_mode, max_workers)

    # åŠ è½½ç–¾ç—…åˆ—è¡¨
    diseases = downloader.load_disease_list()

    # è¯¢é—®ç”¨æˆ·è¦å¤„ç†å¤šå°‘ä¸ªç–¾ç—…
    print(f"\nğŸ’¡ å¹¶å‘ç‰ˆä¸‹è½½æç¤º:")
    print(f"   - æµ‹è¯•å»ºè®®: 100-500 ä¸ªç–¾ç—…")
    print(f"   - ä¸­ç­‰è§„æ¨¡: 1000-2000 ä¸ªç–¾ç—…")
    print(f"   - å…¨é‡ä¸‹è½½: {len(diseases)} ä¸ªç–¾ç—…")
    print(f"   - æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢")
    print(f"   - å¹¶å‘ç‰ˆä¼šè‡ªåŠ¨å»é‡ï¼Œå¤§å¹…æå‡æ•ˆç‡")

    while True:
        try:
            user_input = input(f"\nè¯·è¾“å…¥è¦å¤„ç†çš„ç–¾ç—…æ•°é‡ (1-{len(diseases)}, é»˜è®¤100): ").strip()
            if not user_input:
                max_diseases = 100
            else:
                max_diseases = int(user_input)
                if max_diseases < 1 or max_diseases > len(diseases):
                    print(f"âŒ è¯·è¾“å…¥ 1-{len(diseases)} ä¹‹é—´çš„æ•°å­—")
                    continue
            break
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆï¼Œé€€å‡ºç¨‹åº")
            return

    print(f"\nğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {max_diseases} ä¸ªç–¾ç—…...")

    try:
        # è¿è¡Œå¹¶å‘ä¸‹è½½
        downloader.run_concurrent_download(diseases, max_diseases)

    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ä¸‹è½½è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()